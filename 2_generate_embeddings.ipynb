{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514baba7",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import libraries such as pandas for data manipulation and Azure OpenAI for embedding generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce516da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from sklearn.decomposition import PCA\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836e0424",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "Load the dataset into a pandas DataFrame and inspect the 'combined_text' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d000f211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ghsa_id          cve_id  \\\n",
      "0  GHSA-472w-7w45-g3w5            None   \n",
      "1  GHSA-hmp7-x699-cvhq            None   \n",
      "2  GHSA-rq77-p4h8-4crw  CVE-2025-24358   \n",
      "3  GHSA-vw58-ph65-6rxp  CVE-2024-47822   \n",
      "4  GHSA-7vpp-9cxj-q8gv   CVE-2025-3445   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://api.github.com/advisories/GHSA-472w-7w...   \n",
      "1  https://api.github.com/advisories/GHSA-hmp7-x6...   \n",
      "2  https://api.github.com/advisories/GHSA-rq77-p4...   \n",
      "3  https://api.github.com/advisories/GHSA-vw58-ph...   \n",
      "4  https://api.github.com/advisories/GHSA-7vpp-9c...   \n",
      "\n",
      "                                            html_url  \\\n",
      "0  https://github.com/advisories/GHSA-472w-7w45-g3w5   \n",
      "1  https://github.com/advisories/GHSA-hmp7-x699-cvhq   \n",
      "2  https://github.com/advisories/GHSA-rq77-p4h8-4crw   \n",
      "3  https://github.com/advisories/GHSA-vw58-ph65-6rxp   \n",
      "4  https://github.com/advisories/GHSA-7vpp-9cxj-q8gv   \n",
      "\n",
      "                                             summary  \\\n",
      "0  Pleezer resource exhaustion through uncollecte...   \n",
      "1  Argo Events users can gain privileged access t...   \n",
      "2  gorilla/csrf CSRF vulnerability due to broken ...   \n",
      "3  Directus inserts access token from query strin...   \n",
      "4  mholt/archiver Vulnerable to Path Traversal vi...   \n",
      "\n",
      "                                         description      type  severity  \\\n",
      "0  ### Impact\\nHook scripts in pleezer can be tri...  reviewed    medium   \n",
      "1  ### Summary:\\n\\nA user with permission to crea...  reviewed  critical   \n",
      "2  ### Summary\\n\\ngorilla/csrf is vulnerable to C...  reviewed    medium   \n",
      "3  ### Summary\\nAccess token from query string is...  reviewed    medium   \n",
      "4  A Path Traversal \"Zip Slip\" vulnerability has ...  reviewed      high   \n",
      "\n",
      "                             repository_advisory_url  \\\n",
      "0  https://api.github.com/repos/roderickvd/pleeze...   \n",
      "1  https://api.github.com/repos/argoproj/argo-eve...   \n",
      "2  https://api.github.com/repos/gorilla/csrf/secu...   \n",
      "3  https://api.github.com/repos/directus/directus...   \n",
      "4                                               None   \n",
      "\n",
      "                      source_code_location  ...        github_reviewed_at  \\\n",
      "0    https://github.com/roderickvd/pleezer  ... 2025-04-14 17:49:15+00:00   \n",
      "1  https://github.com/argoproj/argo-events  ... 2025-04-14 17:47:39+00:00   \n",
      "2          https://github.com/gorilla/csrf  ... 2025-04-14 15:26:07+00:00   \n",
      "3     https://github.com/directus/directus  ... 2025-04-14 15:20:40+00:00   \n",
      "4        https://github.com/mholt/archiver  ... 2025-04-14 17:55:15+00:00   \n",
      "\n",
      "           nvd_published_at withdrawn_at  \\\n",
      "0                       NaT          NaT   \n",
      "1                       NaT          NaT   \n",
      "2                       NaT          NaT   \n",
      "3 2024-10-08 18:15:31+00:00          NaT   \n",
      "4 2025-04-13 22:15:12+00:00          NaT   \n",
      "\n",
      "                                     vulnerabilities  \\\n",
      "0  [{'package': {'ecosystem': 'rust', 'name': 'pl...   \n",
      "1  [{'package': {'ecosystem': 'go', 'name': 'gith...   \n",
      "2  [{'package': {'ecosystem': 'go', 'name': 'gith...   \n",
      "3  [{'package': {'ecosystem': 'npm', 'name': '@di...   \n",
      "4  [{'package': {'ecosystem': 'go', 'name': 'gith...   \n",
      "\n",
      "                                     cvss_severities  \\\n",
      "0  {'cvss_v3': {'vector_string': 'CVSS:3.1/AV:N/A...   \n",
      "1  {'cvss_v3': {'vector_string': 'CVSS:3.1/AV:N/A...   \n",
      "2  {'cvss_v3': {'vector_string': None, 'score': 0...   \n",
      "3  {'cvss_v3': {'vector_string': 'CVSS:3.1/AV:L/A...   \n",
      "4  {'cvss_v3': {'vector_string': 'CVSS:3.1/AV:N/A...   \n",
      "\n",
      "                                                cwes  \\\n",
      "0  [{'cwe_id': 'CWE-772', 'name': 'Missing Releas...   \n",
      "1  [{'cwe_id': 'CWE-268', 'name': 'Privilege Chai...   \n",
      "2  [{'cwe_id': 'CWE-352', 'name': 'Cross-Site Req...   \n",
      "3  [{'cwe_id': 'CWE-532', 'name': 'Insertion of S...   \n",
      "4  [{'cwe_id': 'CWE-22', 'name': 'Improper Limita...   \n",
      "\n",
      "                                             credits  \\\n",
      "0                                                 []   \n",
      "1  [{'user': {'login': 'thevilledev', 'id': 30882...   \n",
      "2  [{'user': {'login': 'patrickod', 'id': 84262, ...   \n",
      "3  [{'user': {'login': 'licitdev', 'id': 26413686...   \n",
      "4                                                 []   \n",
      "\n",
      "                                                cvss  \\\n",
      "0  {'vector_string': 'CVSS:3.1/AV:N/AC:L/PR:L/UI:...   \n",
      "1  {'vector_string': 'CVSS:3.1/AV:N/AC:L/PR:L/UI:...   \n",
      "2             {'vector_string': None, 'score': None}   \n",
      "3  {'vector_string': 'CVSS:3.1/AV:L/AC:L/PR:H/UI:...   \n",
      "4  {'vector_string': 'CVSS:3.1/AV:N/AC:H/PR:N/UI:...   \n",
      "\n",
      "                                                epss  \\\n",
      "0                                                  0   \n",
      "1                                                  0   \n",
      "2                                                  0   \n",
      "3  {'percentage': 0.00033000000000000005, 'percen...   \n",
      "4                                                  0   \n",
      "\n",
      "                                       combined_text  \n",
      "0  summary: Pleezer resource exhaustion through u...  \n",
      "1  summary: Argo Events users can gain privileged...  \n",
      "2  summary: gorilla/csrf CSRF vulnerability due t...  \n",
      "3  summary: Directus inserts access token from qu...  \n",
      "4  summary: mholt/archiver Vulnerable to Path Tra...  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\emvictor\\AppData\\Local\\Temp\\ipykernel_243000\\3881876011.py:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  df = pd.read_json('output_folder\\cleaned_advisories.json', lines=True)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_json('output_folder\\cleaned_advisories.json', lines=True)\n",
    "\n",
    "# Inspect the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Check for the presence of the 'combined_text' column\n",
    "if 'combined_text' not in df.columns:\n",
    "    raise ValueError(\"The dataset does not contain a 'combined_text' column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b465ef7",
   "metadata": {},
   "source": [
    "# Preprocess Text Data\n",
    "Perform any necessary preprocessing on the 'combined_text' column, such as removing null values or cleaning text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bdb47fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after preprocessing: 30 rows\n"
     ]
    }
   ],
   "source": [
    "# Preprocess Text Data\n",
    "# Drop rows with null values in the 'combined_text' column\n",
    "df = df.dropna(subset=['combined_text'])\n",
    "\n",
    "# Optional: Add any additional text preprocessing steps here\n",
    "print(f\"Dataset after preprocessing: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b76876",
   "metadata": {},
   "source": [
    "# Generate Two-Dimensional Embeddings\n",
    "Ensure embeddings are two-dimensional and save them in a new column for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579d71a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D embeddings have been successfully saved to 'dataset_with_2d_embeddings.json'.\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Azure OpenAI client correctly\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    api_version=\"2023-05-15\",\n",
    "    azure_endpoint=os.getenv(\"OPENAI_API_BASE\")\n",
    ")\n",
    "\n",
    "# Deployment name for the embeddings model\n",
    "deployment_name = \"text-embedding-3-small\"\n",
    "\n",
    "# Generate embeddings for the text\n",
    "embeddings = []\n",
    "for text in df['combined_text']:\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=deployment_name\n",
    "    )\n",
    "    embedding = response.data[0].embedding\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "# Reduce embeddings to 2 dimensions using PCA\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(embeddings)\n",
    "\n",
    "# Add the 2D embeddings as a new column in the DataFrame\n",
    "df['embeddings_2d'] = embeddings_2d.tolist()\n",
    "\n",
    "# Save the DataFrame with 2D embeddings to a new JSON file\n",
    "df.to_json('output_folder\\\\dataset_with_2d_embeddings.json', orient='records', lines=True)\n",
    "\n",
    "print(\"2D embeddings have been successfully saved to 'dataset_with_2d_embeddings.json'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3eb1ad86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embeddings have 2 dimensions.\n"
     ]
    }
   ],
   "source": [
    "# Check the length of the embeddings array for the first row\n",
    "embedding_length = len(df['embeddings_2d'].iloc[0])\n",
    "print(f\"The embeddings have {embedding_length} dimensions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
