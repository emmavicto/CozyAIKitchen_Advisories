{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e690b245",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "Import libraries including pandas, NumPy, matplotlib, and Azure OpenAI SDK. Remove unused imports from the original notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e19b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import time\n",
    "from openai import AzureOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabb9b1c",
   "metadata": {},
   "source": [
    "# Set Up Azure OpenAI Client\n",
    "Configure the Azure OpenAI client using environment variables for API keys and endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a2bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Azure OpenAI client correctly\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    api_version=\"2023-05-15\",\n",
    "    azure_endpoint=os.getenv(\"OPENAI_API_BASE\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b22dc3d",
   "metadata": {},
   "source": [
    "# Load and Prepare Data\n",
    "Load the RedList data from a local CSV file or other accessible storage. Use pandas for data manipulation instead of PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e4626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with clusters\n",
    "df = pd.read_json('output_folder\\\\clustered_dataset.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31660afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters\n",
    "print(df.groupby('cluster').size().reset_index(name='count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c923d50a",
   "metadata": {},
   "source": [
    "# Generate Summaries Using LLM\n",
    "Define functions to interact with the Azure OpenAI API for generating summaries. Apply these functions to the prepared data using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0d6610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to process each cluster\n",
    "def process_cluster(cluster_df):\n",
    "    JoinDesc = '\\n<threat-Separator>\\n'.join(cluster_df['combined_text'].astype(str))\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": '''\n",
    "                As a seasoned security analyst, you possess a deep understanding of security advisories. Your current task involves analyzing a list of security advisories, each separated by a '<Finding-Separator>'. These advisories have been pre-clustered using an unsupervised machine learning technique, indicating inherent commonalities. Your mission is to delve into these commonalities, uncover underlying patterns, and identify vulnerabilities. Follow this structured format in your response:\n",
    "                1. **Cluster Title**: Create a concise title that encapsulates the core issue of the cluster. If acronyms are used, define them upon first mention.\n",
    "                2. **Cluster Description**: Craft a detailed paragraph exploring the observed similarities among the advisories. Highlight recurring themes, shared vulnerabilities, or common sources of the advisories.\n",
    "                3. **Suggested Actions**: Provide a list of concrete individual actionable steps that directly address the findings. Include specific links to relevant issues or gaps within the data whenever possible, to make the action more standalone. Ensure clarity, leaving no room for ambiguity during implementation.\n",
    "                4. **Summary**: Conclude with a paragraph summarizing key points from the analysis. Emphasize the importance of the suggested actions and their potential impact on improving security.\n",
    "                5. **Data References**: Where applicable, reference specific data points from the input data that support your analysis and suggested actions.\n",
    "\n",
    "                Your goal is to offer practical, feasible guidance tailored to the specifics of this set of security advisories. Engineers should be able to follow these recommendations without additional interpretation.\n",
    "\n",
    "                Example of an incorrect suggested action:\n",
    "                - Patch Management and Security Updates: Develop a streamlined process for managing security updates, especially in environments with complex deployment scenarios. Prioritize the rollout of patches to first-party services before public release.\n",
    "\n",
    "                Example of a correct suggested action:\n",
    "                - Develop a streamlined process for managing security updates, especially in environments with complex deployment scenarios.\n",
    "                - Prioritize the rollout of patches to first-party services before public release.\n",
    "            '''},\n",
    "            {\"role\": \"user\", \"content\": JoinDesc}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=4096,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "    ClusterSummary = response.choices[0].message.content\n",
    "\n",
    "    #print(ClusterSummary)\n",
    "    #print('\\n')\n",
    "    #print('-----------------------------------------------------------------------------------------')\n",
    "\n",
    "    # Return the cluster label and summary for aggregation\n",
    "    return cluster_df['cluster'].iloc[0], ClusterSummary\n",
    "\n",
    "    #time.sleep(5)  # Wait for 5 seconds before the next iteration\n",
    "\n",
    "# Create a new dataframe to store the cluster summaries\n",
    "cluster_summary_df = pd.DataFrame(columns=['cluster', 'ClusterSummary'])\n",
    "\n",
    "# Group the original dataframe by 'cluster'\n",
    "clustergroups = df.groupby(by='cluster')\n",
    "\n",
    "# Process each cluster and store the results in the new dataframe\n",
    "cluster_summaries = []  # Use a list to collect results for better performance\n",
    "for _, grp in clustergroups:\n",
    "    cluster, cluster_summary = process_cluster(grp)\n",
    "    cluster_summaries.append({'cluster': cluster, 'ClusterSummary': cluster_summary})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "cluster_summary_df = pd.DataFrame(cluster_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a0e258",
   "metadata": {},
   "source": [
    "# Export Data\n",
    "Save the processed data with generated summaries to a local file or other accessible storage in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc92e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the display settings for better readability\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Print the dataset with formatted ClusterSummary\n",
    "for index, row in cluster_summary_df.iterrows():\n",
    "    print(f\"Cluster: {row['cluster']}\")\n",
    "    print(f\"ClusterSummary:\\n{row['ClusterSummary']}\")\n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab34082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Data\n",
    "output_file_path = \"output_folder\\\\cluster_summaries.json\"\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "cluster_summary_df.to_json(output_file_path, index=False)\n",
    "print(f\"Generated summaries saved to {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
