{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb8e8e91",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import necessary libraries such as pandas, numpy, scikit-learn, matplotlib, and seaborn for clustering and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e3563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set visualization style\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea27cad5",
   "metadata": {},
   "source": [
    "# Load Dataset with Embeddings\n",
    "Load the previously generated dataset containing embeddings into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820196c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with embeddings\n",
    "df = pd.read_json('output_folder\\\\dataset_with_2d_embeddings.json', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79236ca8",
   "metadata": {},
   "source": [
    "# Prepare Embeddings for Clustering\n",
    "Extract embeddings from the DataFrame and convert them into a suitable format (e.g., numpy array) for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a8e51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings into a numpy array\n",
    "embeddings = np.array(df['embeddings_2d'].tolist(), dtype=np.float64)\n",
    "\n",
    "# Check the shape of the embeddings array\n",
    "print(f\"Shape of DataFrame: {df.shape}\")\n",
    "print(f\"Shape of Embeddings: {embeddings.shape}\")\n",
    "print(f\"First few elements of Embeddings: {embeddings[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceb4ce5",
   "metadata": {},
   "source": [
    "# Determine Optimal Number of Clusters\n",
    "Use methods such as the Elbow method or Silhouette analysis to determine the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d508e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine optimal number of clusters using Elbow method\n",
    "inertia = []\n",
    "k_range = range(2, 15)\n",
    "\n",
    "# Calculate inertia for different values of k\n",
    "# Innertia is the sum of squared distances to the nearest cluster center\n",
    "# It helps to find the optimal number of clusters by looking for the \"elbow\" point in the plot\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(embeddings)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the Elbow curve\n",
    "# The Elbow method is a heuristic used in determining the number of clusters in a dataset.\n",
    "# It involves plotting the explained variation as a function of the number of clusters and selecting the \"elbow\" of the curve as the number of clusters to use.\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_range, inertia, marker='o')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.show()\n",
    "\n",
    "# Determine optimal number of clusters using Silhouette analysis\n",
    "# Silhouette analysis is a method of interpretation and validation of consistency within clusters of data.\n",
    "# The silhouette score measures how similar an object is to its own cluster compared to other clusters.\n",
    "silhouette_scores = []\n",
    "k_range = range(2, 8)  # smaller range for efficiency\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(embeddings)\n",
    "    score = silhouette_score(embeddings, labels)\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "# Plot Silhouette scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_range, silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Analysis for Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266a7894",
   "metadata": {},
   "source": [
    "# Perform Clustering\n",
    "Apply clustering algorithms such as KMeans or DBSCAN to group embeddings into clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61bffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose optimal number of clusters based on previous analysis\n",
    "optimal_k = 3\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(\n",
    "    n_clusters=optimal_k,\n",
    "    init='k-means++',\n",
    "    n_init=20,\n",
    "    max_iter=300,\n",
    "    tol=1e-4,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the model to the embeddings\n",
    "df['cluster'] = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# Inspect cluster distribution\n",
    "print(df['cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51e56e0",
   "metadata": {},
   "source": [
    "# Visualize Clusters\n",
    "Visualize the resulting clusters using dimensionality reduction techniques like PCA or t-SNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f971beba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality using PCA\n",
    "#pca = PCA(n_components=2, random_state=42) \n",
    "#reduced_embeddings = pca.fit_transform(embeddings) \n",
    "\n",
    "# Plot clusters\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(x=embeddings[:,0], y=embeddings[:,1], hue=df['cluster'], palette='viridis', s=50) \n",
    "plt.title('Clusters Visualization using PCA')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df93c92b",
   "metadata": {},
   "source": [
    "# Save Clustered Data\n",
    "Save the DataFrame with cluster labels to a new file for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb61557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save clustered DataFrame to JSON file\n",
    "df.to_json('output_folder\\\\clustered_dataset.json', orient='records', lines=True)\n",
    "\n",
    "print(\"Clustered dataset has been successfully saved to 'clustered_dataset.json'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
